{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqGQyFgkv6ue"
      },
      "source": [
        "# From Text to Structured Knowledge\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In the rapidly evolving landscape of artificial intelligence and natural language processing, the ability to extract structured information from unstructured text is becoming increasingly crucial. This tutorial will guide you through the process of using AI models, specifically OpenAI's API (via together.ai as a provider), to transform raw text into valuable, structured data.\n",
        "\n",
        "As highlighted in \"The Prompt Report: A Systematic Survey of Prompting Techniques\" by [Schulhoff et al. (2023)](https://trigaten.github.io/Prompt_Survey_Site/), the field of prompting techniques is vast and continually expanding. Our tutorial will touch on some of these techniques, demonstrating how they can be applied to real-world tasks such as summarization and information extraction.\n",
        "\n",
        "JSON (JavaScript Object Notation) plays a pivotal role in this process, serving as a bridge between the complex world of human language and the orderly realm of machine processing. Its flexibility allows us to capture the nuances of language while maintaining a structure that's both human-readable and machine-friendly. By mastering the art of extracting structured JSON from AI models, you're not just organizing data; you're opening up a world of possibilities for downstream tasks, scalability, and dynamic applications.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "1. Set up the OpenAI client with custom API keys for use with various providers\n",
        "2. Craft effective prompts for text summarization and information extraction\n",
        "3. Make requests via the OpenAI API for various natural language processing tasks\n",
        "4. Define and use Pydantic models for structured data extraction\n",
        "5. Process and display API responses in useful formats\n",
        "6. Understand the benefits and applications of JSON-structured outputs in AI\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "Structured data extraction is not just about organizing information—it's about unlocking insights and enabling seamless integrations. From powering complex queries and analyses to ensuring smooth API integrations, the skills you'll learn in this tutorial are foundational to many advanced AI applications. Whether you're building a content recommendation system, automating data entry, or developing a question-answering bot, the ability to extract structured information from text is a game-changer.\n",
        "\n",
        "## What We'll Cover\n",
        "\n",
        "1. **Setup and Installation**: We'll start by setting up our environment and installing necessary libraries.\n",
        "2. **Basic Text Summarization**: Learn how to use AI to generate concise summaries of longer texts.\n",
        "3. **Structured Information Extraction**: Dive deep into extracting specific data points from text using predefined schemas.\n",
        "4. **Advanced Techniques**: Explore few-shot learning and other prompting strategies to improve extraction accuracy.\n",
        "5. **Practical Applications**: See how these techniques can be applied to real-world scenarios.\n",
        "\n",
        "Let's embark on this journey to transform the way you interact with and extract value from textual data. By the end of this tutorial, you'll have the tools and knowledge to turn unstructured text into a goldmine of structured, actionable information.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Before we dive in, let's make sure we have all the necessary tools. Run the following command in your Jupyter notebook to install the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyC_upP1v6ui"
      },
      "source": [
        "!pip install openai pydantic -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mermaid-py -q #this is just for visualizations (graphs)"
      ],
      "metadata": {
        "id": "oi6VvcXcyTf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKnRwoGGv6uj"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Now, let's import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXl83Ss4v6uk"
      },
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "import textwrap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-w5XMHCv6uk"
      },
      "source": [
        "# Setting Up the OpenAI Client\n",
        "\n",
        "We'll set up the OpenAI client using a custom API key and base URL. This example uses the Together API, but you can modify it for other providers or the official OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zK0ARZkv6uk"
      },
      "source": [
        "# Setup OpenAI client with custom API key and base URL\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\",\n",
        "    api_key=TOGETHER_API_KEY\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmM8S4sWv6ul"
      },
      "source": [
        "# Text Summarization\n",
        "\n",
        "Let's start with a simple task: summarizing a given text into a single sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "f5ygvG1yv6ul"
      },
      "source": [
        "#@title Example text (hidden for less clutter)\n",
        "text = \"\"\"\n",
        "An ‘AI Scientist’ Is Inventing and Running Its Own Experiments\n",
        "Letting programs learn through “open-ended” experimentation may unlock remarkable new capabilities, as well as new risks.\n",
        "\n",
        "By Will Knight Aug 21, 2024 12:00 PM\n",
        "\n",
        "At first glance, a recent batch of research papers produced by a prominent artificial intelligence lab at the University of British Columbia in Vancouver might not seem that notable. Featuring incremental improvements on existing algorithms and ideas, they read like the contents of a middling AI conference or journal.\n",
        "\n",
        "But the research is, in fact, remarkable. That’s because it’s entirely the work of an “AI scientist” developed at the UBC lab together with researchers from the University of Oxford and a startup called Sakana AI.\n",
        "\n",
        "The project demonstrates an early step toward what might prove a revolutionary trick: letting AI learn by inventing and exploring novel ideas. They’re just not super novel at the moment. Several papers describe tweaks for improving an image-generating technique known as diffusion modeling; another outlines an approach for speeding up learning in deep neural networks.\n",
        "\n",
        "“These are not breakthrough ideas. They’re not wildly creative,” admits Jeff Clune, the professor who leads the UBC lab. “But they seem like pretty cool ideas that somebody might try.”\n",
        "\n",
        "As amazing as today’s AI programs can be, they are limited by their need to consume human-generated training data. If AI programs can instead learn in an open-ended fashion, by experimenting and exploring “interesting” ideas, they might unlock capabilities that extend beyond anything humans have shown them.\n",
        "\n",
        "Clune’s lab had previously developed AI programs designed to learn in this way. For example, one program called Omni tried to generate the behavior of virtual characters in several video-game-like environments, filing away the ones that seemed interesting and then iterating on them with new designs. These programs had previously required hand-coded instructions in order to define interestingness. Large language models, however, provide a way to let these programs identify what’s most intriguing because of their ability to mimic human reasoning. Another recent project from Clune’s lab used this approach to let AI programs dream up the code that allows virtual characters to do all sorts of things within a Roblox-like world.\n",
        "\n",
        "The AI scientist is one example of Clune’s lab riffing on the possibilities. The program comes up with machine learning experiments, decides what seems most promising with the help of an LLM, then writes and runs the necessary code—rinse and repeat. Despite the underwhelming results, Clune says open-ended learning programs, as with language models themselves, could become much more capable as the computer power feeding them is ramped up.\n",
        "\n",
        "“It feels like exploring a new continent or a new planet,” Clune says of the possibilities unlocked by LLMs. “We don't know what we're going to discover, but everywhere we turn, there's something new.”\n",
        "\n",
        "Tom Hope, an assistant professor at the Hebrew University of Jerusalem and a research scientist at the Allen Institute for AI (AI2), says the AI scientist, like LLMs, appears to be highly derivative and cannot be considered reliable. “None of the components are trustworthy right now,” he says.\n",
        "\n",
        "Hope points out that efforts to automate elements of scientific discovery stretch back decades to the work of AI pioneers Allen Newell and Herbert Simon in the 1970s, and, later, the work of Pat Langley at the Institute for the Study of Learning and Expertise. He also notes that several other research groups, including a team at AI2, have recently harnessed LLMs to help with generating hypotheses, writing papers, and reviewing research. “They captured the zeitgeist,” Hope says of the UBC team. “The direction is, of course, incredibly valuable, potentially.”\n",
        "\n",
        "Whether LLM-based systems can ever come up with truly novel or breakthrough ideas also remains unclear. “That’s the trillion-dollar question,” Clune says.\n",
        "\n",
        "Even without scientific breakthroughs, open-ended learning may be vital to developing more capable and useful AI systems in the here and now. A report posted this month by Air Street Capital, an investment firm, highlights the potential of Clune’s work to develop more powerful and reliable AI agents, or programs that autonomously perform useful tasks on computers. The big AI companies all seem to view agents as the next big thing.\n",
        "\n",
        "This week, Clune’s lab revealed its latest open-ended learning project: an AI program that invents and builds AI agents. The AI-designed agents outperform human-designed agents in some tasks, such as math and reading comprehension. The next step will be devising ways to prevent such a system from generating agents that misbehave. “It's potentially dangerous,” Clune says of this work. “We need to get it right, but I think it's possible.”\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the LLM to summarize the text\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Summarize the following in 1 sentence: \" + text},\n",
        "    ],\n",
        ")\n",
        "\n",
        "output = chat_completion.choices[0].message.content\n",
        "print(textwrap.fill(output, width=80))"
      ],
      "metadata": {
        "id": "s9aTgqW88op0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkVKaN0wv6um"
      },
      "source": [
        "# Extracting Structured Information\n",
        "\n",
        "Now, let's move on to a more complex task: extracting structured information from text using a predefined schema.\n",
        "\n",
        "In the ever-evolving landscape of AI and natural language processing, structured data is the key to unlocking powerful insights and seamless integrations. Enter JSON (JavaScript Object Notation), the unsung hero of AI outputs. As we dive into this tutorial, you'll discover how JSON acts as a bridge between the complex world of human language and the orderly realm of machine processing. Its flexibility allows us to capture the nuances of language while maintaining a structure that's both human-readable and machine-friendly. From enabling complex queries and analyses to ensuring smooth API integrations, JSON output isn't just a data format—it's a strategic advantage. By mastering the art of extracting structured JSON from AI models, you're not just organizing data; you're opening up a world of possibilities for downstream tasks, scalability, and dynamic applications. So, buckle up as we explore how to harness the power of JSON in AI, transforming raw language into actionable insights and robust, interconnected systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Structured Output\n",
        "import mermaid as md\n",
        "from mermaid.graph import Graph\n",
        "\n",
        "sequence = Graph('Sequence-diagram',\"\"\"\n",
        "graph TB\n",
        "    subgraph Input\n",
        "    A[fa:fa-file-alt Raw Text Input]\n",
        "    end\n",
        "\n",
        "    subgraph Processing\n",
        "    B[fa:fa-brain AI Model]\n",
        "    C{fa:fa-code Structured JSON Output}\n",
        "    end\n",
        "\n",
        "    subgraph \"Data Handling\"\n",
        "    D[fa:fa-database Data Storage]\n",
        "    E[fa:fa-plug API Integration]\n",
        "    F[fa:fa-chart-bar Data Analysis]\n",
        "    G[fa:fa-chart-pie Visualization]\n",
        "    end\n",
        "\n",
        "    subgraph \"Downstream Applications\"\n",
        "    H[fa:fa-server Database]\n",
        "    I[fa:fa-water Data Lake]\n",
        "    J[fa:fa-globe Web Services]\n",
        "    K[fa:fa-mobile-alt Mobile Apps]\n",
        "    L[fa:fa-robot Machine Learning]\n",
        "    M[fa:fa-lightbulb Business Intelligence]\n",
        "    N[fa:fa-tachometer-alt Dashboards]\n",
        "    O[fa:fa-file-alt Reports]\n",
        "    end\n",
        "\n",
        "    A --> B\n",
        "    B --> C\n",
        "    C --> D\n",
        "    C --> E\n",
        "    C --> F\n",
        "    C --> G\n",
        "\n",
        "    D --> H\n",
        "    D --> I\n",
        "\n",
        "    E --> J\n",
        "    E --> K\n",
        "\n",
        "    F --> L\n",
        "    F --> M\n",
        "\n",
        "    G --> N\n",
        "    G --> O\n",
        "\n",
        "    style A fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style B fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style C fill:#bfb,stroke:#333,stroke-width:4px\n",
        "    style D fill:#ff9,stroke:#333,stroke-width:2px\n",
        "    style E fill:#9ff,stroke:#333,stroke-width:2px\n",
        "    style F fill:#f99,stroke:#333,stroke-width:2px\n",
        "    style G fill:#9f9,stroke:#333,stroke-width:2px\n",
        "\n",
        "    classDef downstream fill:#f4f4f4,stroke:#333,stroke-width:1px\n",
        "    class H,I,J,K,L,M,N,O downstream\n",
        "\n",
        "    classDef popular stroke:#f66,stroke-width:4px;\n",
        "    class C popular;\n",
        "\"\"\")\n",
        "render = md.Mermaid(sequence)\n",
        "render # !! note this only works in the notebook that rendered the html."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "cellView": "form",
        "id": "FRx77mMaylwO",
        "outputId": "6d22af4c-8acf-4d99-8f99-8961e4188005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mermaid.__main__.Mermaid at 0x7ad3daee7b50>"
            ],
            "text/html": [
              "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" class=\"flowchart\" style=\"max-width: 1799.40625px;\" viewBox=\"0 0 1799.40625 882.515625\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span{color:#333;}#mermaid-svg .cluster-label span p{background-color:transparent;}#mermaid-svg .label text,#mermaid-svg span{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .rough-node .label text,#mermaid-svg .node .label text{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .node .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}#mermaid-svg .downstream&gt;*{fill:#f4f4f4!important;stroke:#333!important;stroke-width:1px!important;}#mermaid-svg .downstream span{fill:#f4f4f4!important;stroke:#333!important;stroke-width:1px!important;}#mermaid-svg .popular&gt;*{stroke:#f66!important;stroke-width:4px!important;}#mermaid-svg .popular span{stroke:#f66!important;stroke-width:4px!important;}</style><g><marker id=\"mermaid-svg_flowchart-v2-pointEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-pointStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossEnd\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossStart\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"><g class=\"cluster \" id=\"subGraph3\" data-look=\"classic\"><rect style=\"\" x=\"8\" y=\"770.515625\" width=\"1783.40625\" height=\"104\"/><g class=\"cluster-label \" transform=\"translate(809.6875, 770.515625)\"><foreignObject width=\"180.03125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Downstream Applications</p></span></div></foreignObject></g></g><g class=\"cluster \" id=\"subGraph2\" data-look=\"classic\"><rect style=\"\" x=\"36.75390625\" y=\"616.515625\" width=\"1725.94140625\" height=\"104\"/><g class=\"cluster-label \" transform=\"translate(849.537109375, 616.515625)\"><foreignObject width=\"100.375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Data Handling</p></span></div></foreignObject></g></g><g class=\"cluster \" id=\"Processing\" data-look=\"classic\"><rect style=\"\" x=\"156.99609375\" y=\"162\" width=\"1475.875\" height=\"404.515625\"/><g class=\"cluster-label \" transform=\"translate(857.97265625, 162)\"><foreignObject width=\"73.921875\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Processing</p></span></div></foreignObject></g></g><g class=\"cluster \" id=\"Input\" data-look=\"classic\"><rect style=\"\" x=\"764.125\" y=\"8\" width=\"253.375\" height=\"104\"/><g class=\"cluster-label \" transform=\"translate(872.2109375, 8)\"><foreignObject width=\"37.203125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Input</p></span></div></foreignObject></g></g></g><g class=\"edgePaths\"><path d=\"M890.813,87L890.813,91.167C890.813,95.333,890.813,103.667,890.813,112C890.813,120.333,890.813,128.667,890.813,137C890.813,145.333,890.813,153.667,890.813,159.917C890.813,166.167,890.813,170.333,890.813,173.833C890.813,177.333,890.813,180.167,890.813,181.583L890.813,183\" id=\"L_A_B_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M890.813,241L890.813,245.167C890.813,249.333,890.813,257.667,890.854,263.958C890.896,270.25,890.979,274.5,891.049,278.083C891.12,281.667,891.177,284.584,891.205,286.042L891.234,287.501\" id=\"L_B_C_1\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M788.893,439.596L693.572,460.749C598.251,481.903,407.61,524.209,312.289,549.529C216.969,574.849,216.969,583.182,216.969,591.516C216.969,599.849,216.969,608.182,216.969,614.432C216.969,620.682,216.969,624.849,216.969,628.349C216.969,631.849,216.969,634.682,216.969,636.099L216.969,637.516\" id=\"L_C_D_2\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M812.992,463.695L784.174,480.832C755.356,497.968,697.721,532.242,668.904,553.545C640.086,574.849,640.086,583.182,640.086,591.516C640.086,599.849,640.086,608.182,640.086,614.432C640.086,620.682,640.086,624.849,640.086,628.349C640.086,631.849,640.086,634.682,640.086,636.099L640.086,637.516\" id=\"L_C_E_3\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M966.738,466.59L991.988,483.245C1017.238,499.899,1067.738,533.207,1092.988,554.028C1118.238,574.849,1118.238,583.182,1118.238,591.516C1118.238,599.849,1118.238,608.182,1118.238,614.432C1118.238,620.682,1118.238,624.849,1118.238,628.349C1118.238,631.849,1118.238,634.682,1118.238,636.099L1118.238,637.516\" id=\"L_C_F_4\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M994.508,438.82L1094.366,460.102C1194.223,481.385,1393.938,523.95,1493.795,549.4C1593.652,574.849,1593.652,583.182,1593.652,591.516C1593.652,599.849,1593.652,608.182,1593.652,614.432C1593.652,620.682,1593.652,624.849,1593.652,628.349C1593.652,631.849,1593.652,634.682,1593.652,636.099L1593.652,637.516\" id=\"L_C_G_5\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M164.624,695.516L156.546,699.682C148.468,703.849,132.312,712.182,124.234,720.516C116.156,728.849,116.156,737.182,116.156,745.516C116.156,753.849,116.156,762.182,116.156,768.432C116.156,774.682,116.156,778.849,116.156,782.349C116.156,785.849,116.156,788.682,116.156,790.099L116.156,791.516\" id=\"L_D_H_6\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M268.531,695.516L276.488,699.682C284.445,703.849,300.359,712.182,308.316,720.516C316.273,728.849,316.273,737.182,316.273,745.516C316.273,753.849,316.273,762.182,316.273,768.432C316.273,774.682,316.273,778.849,316.273,782.349C316.273,785.849,316.273,788.682,316.273,790.099L316.273,791.516\" id=\"L_D_I_7\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M583.137,695.516L574.348,699.682C565.56,703.849,547.983,712.182,539.195,720.516C530.406,728.849,530.406,737.182,530.406,745.516C530.406,753.849,530.406,762.182,530.406,768.432C530.406,774.682,530.406,778.849,530.406,782.349C530.406,785.849,530.406,788.682,530.406,790.099L530.406,791.516\" id=\"L_E_J_8\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M696.252,695.516L704.92,699.682C713.587,703.849,730.923,712.182,739.59,720.516C748.258,728.849,748.258,737.182,748.258,745.516C748.258,753.849,748.258,762.182,748.258,768.432C748.258,774.682,748.258,778.849,748.258,782.349C748.258,785.849,748.258,788.682,748.258,790.099L748.258,791.516\" id=\"L_E_K_9\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M1048.408,695.516L1037.632,699.682C1026.855,703.849,1005.303,712.182,994.526,720.516C983.75,728.849,983.75,737.182,983.75,745.516C983.75,753.849,983.75,762.182,983.75,768.432C983.75,774.682,983.75,778.849,983.75,782.349C983.75,785.849,983.75,788.682,983.75,790.099L983.75,791.516\" id=\"L_F_L_10\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M1187.286,695.516L1197.941,699.682C1208.597,703.849,1229.908,712.182,1240.563,720.516C1251.219,728.849,1251.219,737.182,1251.219,745.516C1251.219,753.849,1251.219,762.182,1251.219,768.432C1251.219,774.682,1251.219,778.849,1251.219,782.349C1251.219,785.849,1251.219,788.682,1251.219,790.099L1251.219,791.516\" id=\"L_F_M_11\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M1542.307,695.516L1534.384,699.682C1526.46,703.849,1510.613,712.182,1502.689,720.516C1494.766,728.849,1494.766,737.182,1494.766,745.516C1494.766,753.849,1494.766,762.182,1494.766,768.432C1494.766,774.682,1494.766,778.849,1494.766,782.349C1494.766,785.849,1494.766,788.682,1494.766,790.099L1494.766,791.516\" id=\"L_G_N_12\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M1644.214,695.516L1652.017,699.682C1659.82,703.849,1675.426,712.182,1683.228,720.516C1691.031,728.849,1691.031,737.182,1691.031,745.516C1691.031,753.849,1691.031,762.182,1691.031,768.432C1691.031,774.682,1691.031,778.849,1691.031,782.349C1691.031,785.849,1691.031,788.682,1691.031,790.099L1691.031,791.516\" id=\"L_G_O_13\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default  \" id=\"flowchart-A-0\" transform=\"translate(890.8125, 60)\"><rect class=\"basic label-container\" style=\"fill:#f9f !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-91.6875\" y=\"-27\" width=\"183.375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-61.6875, -12)\"><rect/><foreignObject width=\"123.375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-file-alt\"></i> Raw Text Input</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-B-1\" transform=\"translate(890.8125, 214)\"><rect class=\"basic label-container\" style=\"fill:#bbf !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-70.4765625\" y=\"-27\" width=\"140.953125\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-40.4765625, -12)\"><rect/><foreignObject width=\"80.953125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-brain\"></i> AI Model</p></span></div></foreignObject></g></g><g class=\"node default popular \" id=\"flowchart-C-2\" transform=\"translate(890.8125, 416.2578125)\"><polygon points=\"125.2578125,0 250.515625,-125.2578125 125.2578125,-250.515625 0,-125.2578125\" class=\"label-container\" transform=\"translate(-125.2578125,125.2578125)\" style=\"stroke:#333 !important;stroke-width:4px !important;fill:#bfb !important\"/><g class=\"label\" style=\"\" transform=\"translate(-98.2578125, -12)\"><rect/><foreignObject width=\"196.515625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-code\"></i> Structured JSON Output</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-D-3\" transform=\"translate(216.96875, 668.515625)\"><rect class=\"basic label-container\" style=\"fill:#ff9 !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-85.3125\" y=\"-27\" width=\"170.625\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-55.3125, -12)\"><rect/><foreignObject width=\"110.625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-database\"></i> Data Storage</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-E-4\" transform=\"translate(640.0859375, 668.515625)\"><rect class=\"basic label-container\" style=\"fill:#9ff !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-91.3671875\" y=\"-27\" width=\"182.734375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-61.3671875, -12)\"><rect/><foreignObject width=\"122.734375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-plug\"></i> API Integration</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-F-5\" transform=\"translate(1118.23828125, 668.515625)\"><rect class=\"basic label-container\" style=\"fill:#f99 !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-87.21875\" y=\"-27\" width=\"174.4375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-57.21875, -12)\"><rect/><foreignObject width=\"114.4375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-chart-bar\"></i> Data Analysis</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-G-6\" transform=\"translate(1593.65234375, 668.515625)\"><rect class=\"basic label-container\" style=\"fill:#9f9 !important;stroke:#333 !important;stroke-width:2px !important\" data-id=\"abc\" data-et=\"node\" x=\"-86.8203125\" y=\"-27\" width=\"173.640625\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-56.8203125, -12)\"><rect/><foreignObject width=\"113.640625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-chart-pie\"></i> Visualization</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-H-7\" transform=\"translate(116.15625, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-73.15625\" y=\"-27\" width=\"146.3125\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-43.15625, -12)\"><rect/><foreignObject width=\"86.3125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-server\"></i> Database</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-I-8\" transform=\"translate(316.2734375, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-76.9609375\" y=\"-27\" width=\"153.921875\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-46.9609375, -12)\"><rect/><foreignObject width=\"93.921875\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-water\"></i> Data Lake</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-J-9\" transform=\"translate(530.40625, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-87.171875\" y=\"-27\" width=\"174.34375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-57.171875, -12)\"><rect/><foreignObject width=\"114.34375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-globe\"></i> Web Services</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-K-10\" transform=\"translate(748.2578125, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-80.6796875\" y=\"-27\" width=\"161.359375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-50.6796875, -12)\"><rect/><foreignObject width=\"101.359375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-mobile-alt\"></i> Mobile Apps</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-L-11\" transform=\"translate(983.75, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-104.8125\" y=\"-27\" width=\"209.625\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-74.8125, -12)\"><rect/><foreignObject width=\"149.625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-robot\"></i> Machine Learning</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-M-12\" transform=\"translate(1251.21875, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-112.65625\" y=\"-27\" width=\"225.3125\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-82.65625, -12)\"><rect/><foreignObject width=\"165.3125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-lightbulb\"></i> Business Intelligence</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-N-13\" transform=\"translate(1494.765625, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-80.890625\" y=\"-27\" width=\"161.78125\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-50.890625, -12)\"><rect/><foreignObject width=\"101.78125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-tachometer-alt\"></i> Dashboards</p></span></div></foreignObject></g></g><g class=\"node default downstream \" id=\"flowchart-O-14\" transform=\"translate(1691.03125, 822.515625)\"><rect class=\"basic label-container\" style=\"fill:#f4f4f4 !important;stroke:#333 !important;stroke-width:1px !important\" data-id=\"abc\" data-et=\"node\" x=\"-65.375\" y=\"-27\" width=\"130.75\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-35.375, -12)\"><rect/><foreignObject width=\"70.75\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p><i class=\"fa fa-file-alt\"></i> Reports</p></span></div></foreignObject></g></g></g></g></g></svg>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real-World Example: AI-Powered Call Center Analytics\n",
        "\n",
        "Let's walk through a scenario where a large e-commerce company uses AI to analyze customer service calls. This example demonstrates how structured JSON output enables a powerful, integrated system for deriving actionable insights from customer interactions.\n",
        "\n",
        "1. **Audio Input**\n",
        "   - A customer calls the support line with a complaint about a delayed shipment.\n",
        "   - The call is recorded as an audio file.\n",
        "\n",
        "2. **Speech-to-Text Transcription**\n",
        "   - An AI model transcribes the audio to text.\n",
        "   - Output: Raw text of the conversation.\n",
        "\n",
        "3. **AI Model Processing**\n",
        "   - The transcribed text is fed into an AI model for analysis.\n",
        "   - The model is trained to extract key information from customer service conversations.\n",
        "\n",
        "4. **Structured JSON Output**\n",
        "   - The AI model produces a structured JSON output containing:\n",
        "     ```json\n",
        "     {\n",
        "       \"call_id\": \"CS12345\",\n",
        "       \"timestamp\": \"2024-05-15T14:30:00Z\",\n",
        "       \"customer_id\": \"CUST9876\",\n",
        "       \"issue_type\": \"delayed_shipment\",\n",
        "       \"sentiment\": \"frustrated\",\n",
        "       \"product_mentioned\": \"wireless_headphones\",\n",
        "       \"order_number\": \"ORD5678\",\n",
        "       \"resolution_status\": \"escalated\",\n",
        "       \"key_phrases\": [\n",
        "         \"where is my package\",\n",
        "         \"need it urgently\",\n",
        "         \"disappointed with service\"\n",
        "       ],\n",
        "       \"agent_performance\": {\n",
        "         \"empathy_score\": 0.8,\n",
        "         \"resolution_attempt\": true,\n",
        "         \"follow_up_required\": true\n",
        "       }\n",
        "     }\n",
        "     ```\n",
        "\n",
        "5. **Downstream Applications**\n",
        "   - **Data Storage**:\n",
        "     - The structured JSON is stored in a NoSQL database for quick retrieval.\n",
        "     - It's also added to a data lake for long-term storage and analysis.\n",
        "   \n",
        "   - **API Integration**:\n",
        "     - The JSON is sent via API to the company's CRM system, updating the customer's profile.\n",
        "     - A notification is automatically sent to the logistics department about the delayed shipment.\n",
        "   \n",
        "   - **Data Analysis**:\n",
        "     - Machine learning models analyze patterns in issues and sentiments across multiple calls.\n",
        "     - Business intelligence tools generate reports on common problems and their resolutions.\n",
        "   \n",
        "   - **Visualization**:\n",
        "     - A real-time dashboard shows current customer sentiment and open issues.\n",
        "     - Weekly reports visualize trends in customer satisfaction and common complaints.\n",
        "\n",
        "6. **Actionable Insights**\n",
        "   - The shipping department identifies a recurring delay issue with a particular carrier.\n",
        "   - Customer service training is updated to improve empathy scores based on successful interactions.\n",
        "   - Product development receives feedback about the wireless headphones frequently mentioned in complaints.\n",
        "\n",
        "7. **Continuous Improvement**\n",
        "   - The structured data feeds back into AI model training, continuously improving its accuracy and capabilities.\n",
        "\n",
        "This example illustrates how structured JSON output serves as the backbone of an integrated, data-driven approach to customer service. From the initial audio input to actionable business insights, each step of the process relies on the clear, structured format of the JSON data to enable seamless communication between different systems and teams."
      ],
      "metadata": {
        "id": "9CtIhECHz3sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Schema\n",
        "\n",
        "We'll use Pydantic to define a schema for the information we want to extract:"
      ],
      "metadata": {
        "id": "5waySdRWyjAt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0uzvrnCv6um"
      },
      "source": [
        "class ExtractScheme(BaseModel):\n",
        "    title: str = Field(description=\"Title of the news article\")\n",
        "    publication_date: str = Field(description=\"Date when the article was published\")\n",
        "    main_topic: str = Field(description=\"Primary topic or focus of the article\")\n",
        "    research_description: str = Field(description=\"Brief description of the AI research or development\")\n",
        "    institutions_involved: List[str] = Field(description=\"Organizations or institutions mentioned in the research\")\n",
        "    key_researchers: List[str] = Field(description=\"Main researchers or scientists mentioned\")\n",
        "    ai_technologies: List[str] = Field(description=\"AI technologies or methods discussed\")\n",
        "    research_outcomes: List[str] = Field(description=\"Key results or findings from the research\")\n",
        "    potential_impacts: List[str] = Field(description=\"Potential significance or impacts of the research\")\n",
        "    ethical_concerns: Optional[List[str]] = Field(description=\"Ethical or societal concerns related to the research\")\n",
        "    keywords: List[str] = Field(description=\"Key terms or phrases from the article\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ You can absolutely use LLMs to help you define such schemas! Typing this manually is not a nessary skill..."
      ],
      "metadata": {
        "id": "_hNst8GwwVIE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spr46j0ov6um"
      },
      "source": [
        "## Extracting Information\n",
        "\n",
        "Now, let's use this schema to extract information from our text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLGGMQpov6um"
      },
      "source": [
        "# Convert the Pydantic schema to a JSON schema\n",
        "json_schema = str(ExtractScheme.model_json_schema())\n",
        "\n",
        "# Call the LLM with the JSON schema\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a text related to AI research and technology. Follow the schema provided below to extract the relevant details. Do not invent information that is not in the provided text. Output JSON only.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Extract case information from the following text: {text}\\nUse the following JSON schema: {json_schema}\"\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Parse and print the extracted information\n",
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCyWzDv_v6un"
      },
      "source": [
        "## Extracting Information with Enforced JSON Schema\n",
        "\n",
        "Now, let's use the `response_format` parameter to enforce the JSON schema in the API response. This ensures that the output strictly adheres to our defined structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZfr5qOav6un"
      },
      "source": [
        "# Call the LLM with the JSON schema enforced in the response_format\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    response_format={\"type\": \"json_object\", \"schema\": ExtractScheme.model_json_schema()},\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a text related to AI research and technology. Follow the schema provided to extract the relevant details. Do not invent information that is not in the provided text.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Extract case information from the following text: {text}\"\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Parse and print the extracted information\n",
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGL0J5Rnv6un"
      },
      "source": [
        "This approach has several advantages:\n",
        "\n",
        "1. **Strict Adherence to Schema**: The API will ensure that the response strictly follows the defined JSON schema, reducing the need for additional validation on your end.\n",
        "\n",
        "2. **Consistent Output**: You're guaranteed to receive a response in the expected format, making it easier to process and use the extracted information in your application.\n",
        "\n",
        "3. **Error Handling**: If the model can't generate a response that matches the schema, it will return an error, allowing you to handle such cases appropriately.\n",
        "\n",
        "4. **Improved Efficiency**: By specifying the exact structure you need, you can potentially reduce the amount of post-processing required on the API's output.\n",
        "\n",
        "Note that not all models support the `response_format` parameter. Make sure to check the documentation for the specific model you're using to ensure compatibility with this feature.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding few-shot examples\n",
        "\n",
        "Now that we've seen how to extract structured information from a single article, let's explore how we can use few-shot learning to improve our extraction process for new articles. Few-shot learning allows our model to learn from a small number of examples and apply that knowledge to new, unseen data."
      ],
      "metadata": {
        "id": "cM_6jKWa1tXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Few-shot example viz\n",
        "import mermaid as md\n",
        "from mermaid.graph import Graph\n",
        "\n",
        "sequence = Graph('Sequence-diagram',\"\"\"\n",
        "sequenceDiagram\n",
        "    participant Human as Human\n",
        "    participant Claude35 as Claude 3.5<br/>(Large Model)\n",
        "    participant LLaMA as LLaMA 3.1 8B<br/>(Small Model)\n",
        "    participant JSON as JSON Schema\n",
        "\n",
        "    rect rgb(240, 240, 255)\n",
        "    Note over Human,JSON: Initial Setup\n",
        "    Human->>Claude35: Provide initial text and extraction task\n",
        "    Note over Claude35: Generates high-quality<br/>structured extraction\n",
        "    Claude35-->>Human: Return example_output (JSON)\n",
        "    Human->>JSON: Define ExtractScheme\n",
        "    end\n",
        "\n",
        "    rect rgb(255, 240, 240)\n",
        "    Note over Human,LLaMA: API Request\n",
        "    Human->>LLaMA: Send API request with:\n",
        "    Note over Human,LLaMA: 1. System prompt<br/>2. Initial text<br/>3. example_output from Claude 3.5<br/>4. New text for extraction<br/>5. JSON schema\n",
        "    end\n",
        "\n",
        "    rect rgb(240, 255, 240)\n",
        "    Note over LLaMA: Processing\n",
        "    LLaMA->>LLaMA: Process request using few-shot learning\n",
        "    Note over LLaMA: Learn from Claude 3.5's example<br/>Apply to new text<br/>Conform to JSON schema\n",
        "    end\n",
        "\n",
        "    rect rgb(255, 255, 240)\n",
        "    Note over LLaMA,Human: Results\n",
        "    LLaMA-->>Human: Return structured extraction for new text\n",
        "    Human->>Human: Parse and analyze results\n",
        "    end\n",
        "\"\"\")\n",
        "render = md.Mermaid(sequence)\n",
        "render # !! note this only works in the notebook that rendered the html."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "1_N2l-3y3f7L",
        "outputId": "0c371775-12df-47d0-b64c-9cfdebacf975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mermaid.__main__.Mermaid at 0x7ad3daee45b0>"
            ],
            "text/html": [
              "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 979px;\" viewBox=\"-64 -10 979 1173\" role=\"graphics-document document\" aria-roledescription=\"sequence\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css\");</style><rect x=\"-14\" y=\"848\" fill=\"rgb(255, 255, 240)\" width=\"639\" height=\"219\" class=\"rect\"/><rect x=\"454\" y=\"606\" fill=\"rgb(240, 255, 240)\" width=\"274\" height=\"232\" class=\"rect\"/><rect x=\"40\" y=\"356\" fill=\"rgb(255, 240, 240)\" width=\"585\" height=\"240\" class=\"rect\"/><rect x=\"40\" y=\"75\" fill=\"rgb(240, 240, 255)\" width=\"785\" height=\"271\" class=\"rect\"/><g><rect x=\"715\" y=\"1087\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"JSON\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"790\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"790\" dy=\"0\">JSON Schema</tspan></text></g><g><rect x=\"515\" y=\"1087\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLaMA\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"590\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"590\" dy=\"-8\">LLaMA 3.1 8B</tspan></text><text x=\"590\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"590\" dy=\"8\">(Small Model)</tspan></text></g><g><rect x=\"315\" y=\"1087\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Claude35\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"390\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"390\" dy=\"-8\">Claude 3.5</tspan></text><text x=\"390\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"390\" dy=\"8\">(Large Model)</tspan></text></g><g><rect x=\"0\" y=\"1087\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Human\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"75\" y=\"1119.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">Human</tspan></text></g><g><line id=\"actor3\" x1=\"790\" y1=\"5\" x2=\"790\" y2=\"1087\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"JSON\"/><g id=\"root-3\"><rect x=\"715\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"JSON\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"790\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"790\" dy=\"0\">JSON Schema</tspan></text></g></g><g><line id=\"actor2\" x1=\"590\" y1=\"5\" x2=\"590\" y2=\"1087\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"LLaMA\"/><g id=\"root-2\"><rect x=\"515\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLaMA\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"590\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"590\" dy=\"-8\">LLaMA 3.1 8B</tspan></text><text x=\"590\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"590\" dy=\"8\">(Small Model)</tspan></text></g></g><g><line id=\"actor1\" x1=\"390\" y1=\"5\" x2=\"390\" y2=\"1087\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"Claude35\"/><g id=\"root-1\"><rect x=\"315\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Claude35\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"390\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"390\" dy=\"-8\">Claude 3.5</tspan></text><text x=\"390\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"390\" dy=\"8\">(Large Model)</tspan></text></g></g><g><line id=\"actor0\" x1=\"75\" y1=\"5\" x2=\"75\" y2=\"1087\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"Human\"/><g id=\"root-0\"><rect x=\"0\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Human\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"75\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">Human</tspan></text></g></g><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .actor{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg text.actor&gt;tspan{fill:black;stroke:none;}#mermaid-svg .actor-line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-svg .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#333;}#mermaid-svg .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#333;}#mermaid-svg #arrowhead path{fill:#333;stroke:#333;}#mermaid-svg .sequenceNumber{fill:white;}#mermaid-svg #sequencenumber{fill:#333;}#mermaid-svg #crosshead path{fill:#333;stroke:#333;}#mermaid-svg .messageText{fill:#333;stroke:none;}#mermaid-svg .labelBox{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .labelText,#mermaid-svg .labelText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopText,#mermaid-svg .loopText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-svg .note{stroke:#aaaa33;fill:#fff5ad;}#mermaid-svg .noteText,#mermaid-svg .noteText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .activation0{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation1{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation2{fill:#f4f4f4;stroke:#666;}#mermaid-svg .actorPopupMenu{position:absolute;}#mermaid-svg .actorPopupMenuPanel{position:absolute;fill:#ECECFF;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#mermaid-svg .actor-man line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .actor-man circle,#mermaid-svg line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;stroke-width:2px;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g/><defs><symbol id=\"computer\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M2 2v13h20v-13h-20zm18 11h-16v-9h16v9zm-10.228 6l.466-1h3.524l.467 1h-4.457zm14.228 3h-24l2-6h2.104l-1.33 4h18.45l-1.297-4h2.073l2 6zm-5-10h-14v-7h14v7z\"/></symbol></defs><defs><symbol id=\"database\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path transform=\"scale(.5)\" d=\"M12.258.001l.256.004.255.005.253.008.251.01.249.012.247.015.246.016.242.019.241.02.239.023.236.024.233.027.231.028.229.031.225.032.223.034.22.036.217.038.214.04.211.041.208.043.205.045.201.046.198.048.194.05.191.051.187.053.183.054.18.056.175.057.172.059.168.06.163.061.16.063.155.064.15.066.074.033.073.033.071.034.07.034.069.035.068.035.067.035.066.035.064.036.064.036.062.036.06.036.06.037.058.037.058.037.055.038.055.038.053.038.052.038.051.039.05.039.048.039.047.039.045.04.044.04.043.04.041.04.04.041.039.041.037.041.036.041.034.041.033.042.032.042.03.042.029.042.027.042.026.043.024.043.023.043.021.043.02.043.018.044.017.043.015.044.013.044.012.044.011.045.009.044.007.045.006.045.004.045.002.045.001.045v17l-.001.045-.002.045-.004.045-.006.045-.007.045-.009.044-.011.045-.012.044-.013.044-.015.044-.017.043-.018.044-.02.043-.021.043-.023.043-.024.043-.026.043-.027.042-.029.042-.03.042-.032.042-.033.042-.034.041-.036.041-.037.041-.039.041-.04.041-.041.04-.043.04-.044.04-.045.04-.047.039-.048.039-.05.039-.051.039-.052.038-.053.038-.055.038-.055.038-.058.037-.058.037-.06.037-.06.036-.062.036-.064.036-.064.036-.066.035-.067.035-.068.035-.069.035-.07.034-.071.034-.073.033-.074.033-.15.066-.155.064-.16.063-.163.061-.168.06-.172.059-.175.057-.18.056-.183.054-.187.053-.191.051-.194.05-.198.048-.201.046-.205.045-.208.043-.211.041-.214.04-.217.038-.22.036-.223.034-.225.032-.229.031-.231.028-.233.027-.236.024-.239.023-.241.02-.242.019-.246.016-.247.015-.249.012-.251.01-.253.008-.255.005-.256.004-.258.001-.258-.001-.256-.004-.255-.005-.253-.008-.251-.01-.249-.012-.247-.015-.245-.016-.243-.019-.241-.02-.238-.023-.236-.024-.234-.027-.231-.028-.228-.031-.226-.032-.223-.034-.22-.036-.217-.038-.214-.04-.211-.041-.208-.043-.204-.045-.201-.046-.198-.048-.195-.05-.19-.051-.187-.053-.184-.054-.179-.056-.176-.057-.172-.059-.167-.06-.164-.061-.159-.063-.155-.064-.151-.066-.074-.033-.072-.033-.072-.034-.07-.034-.069-.035-.068-.035-.067-.035-.066-.035-.064-.036-.063-.036-.062-.036-.061-.036-.06-.037-.058-.037-.057-.037-.056-.038-.055-.038-.053-.038-.052-.038-.051-.039-.049-.039-.049-.039-.046-.039-.046-.04-.044-.04-.043-.04-.041-.04-.04-.041-.039-.041-.037-.041-.036-.041-.034-.041-.033-.042-.032-.042-.03-.042-.029-.042-.027-.042-.026-.043-.024-.043-.023-.043-.021-.043-.02-.043-.018-.044-.017-.043-.015-.044-.013-.044-.012-.044-.011-.045-.009-.044-.007-.045-.006-.045-.004-.045-.002-.045-.001-.045v-17l.001-.045.002-.045.004-.045.006-.045.007-.045.009-.044.011-.045.012-.044.013-.044.015-.044.017-.043.018-.044.02-.043.021-.043.023-.043.024-.043.026-.043.027-.042.029-.042.03-.042.032-.042.033-.042.034-.041.036-.041.037-.041.039-.041.04-.041.041-.04.043-.04.044-.04.046-.04.046-.039.049-.039.049-.039.051-.039.052-.038.053-.038.055-.038.056-.038.057-.037.058-.037.06-.037.061-.036.062-.036.063-.036.064-.036.066-.035.067-.035.068-.035.069-.035.07-.034.072-.034.072-.033.074-.033.151-.066.155-.064.159-.063.164-.061.167-.06.172-.059.176-.057.179-.056.184-.054.187-.053.19-.051.195-.05.198-.048.201-.046.204-.045.208-.043.211-.041.214-.04.217-.038.22-.036.223-.034.226-.032.228-.031.231-.028.234-.027.236-.024.238-.023.241-.02.243-.019.245-.016.247-.015.249-.012.251-.01.253-.008.255-.005.256-.004.258-.001.258.001zm-9.258 20.499v.01l.001.021.003.021.004.022.005.021.006.022.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.023.018.024.019.024.021.024.022.025.023.024.024.025.052.049.056.05.061.051.066.051.07.051.075.051.079.052.084.052.088.052.092.052.097.052.102.051.105.052.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.048.144.049.147.047.152.047.155.047.16.045.163.045.167.043.171.043.176.041.178.041.183.039.187.039.19.037.194.035.197.035.202.033.204.031.209.03.212.029.216.027.219.025.222.024.226.021.23.02.233.018.236.016.24.015.243.012.246.01.249.008.253.005.256.004.259.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.021.224-.024.22-.026.216-.027.212-.028.21-.031.205-.031.202-.034.198-.034.194-.036.191-.037.187-.039.183-.04.179-.04.175-.042.172-.043.168-.044.163-.045.16-.046.155-.046.152-.047.148-.048.143-.049.139-.049.136-.05.131-.05.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.053.083-.051.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.05.023-.024.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.023.01-.022.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.127l-.077.055-.08.053-.083.054-.085.053-.087.052-.09.052-.093.051-.095.05-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.045-.118.044-.12.043-.122.042-.124.042-.126.041-.128.04-.13.04-.132.038-.134.038-.135.037-.138.037-.139.035-.142.035-.143.034-.144.033-.147.032-.148.031-.15.03-.151.03-.153.029-.154.027-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.01-.179.008-.179.008-.181.006-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.006-.179-.008-.179-.008-.178-.01-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.027-.153-.029-.151-.03-.15-.03-.148-.031-.146-.032-.145-.033-.143-.034-.141-.035-.14-.035-.137-.037-.136-.037-.134-.038-.132-.038-.13-.04-.128-.04-.126-.041-.124-.042-.122-.042-.12-.044-.117-.043-.116-.045-.113-.045-.112-.046-.109-.047-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.05-.093-.052-.09-.051-.087-.052-.085-.053-.083-.054-.08-.054-.077-.054v4.127zm0-5.654v.011l.001.021.003.021.004.021.005.022.006.022.007.022.009.022.01.022.011.023.012.023.013.023.015.024.016.023.017.024.018.024.019.024.021.024.022.024.023.025.024.024.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.052.11.051.114.051.119.052.123.05.127.051.131.05.135.049.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.044.171.042.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.022.23.02.233.018.236.016.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.012.241-.015.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.048.139-.05.136-.049.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.051.051-.049.023-.025.023-.024.021-.025.02-.024.019-.024.018-.024.017-.024.015-.023.014-.023.013-.024.012-.022.01-.023.01-.023.008-.022.006-.022.006-.022.004-.021.004-.022.001-.021.001-.021v-4.139l-.077.054-.08.054-.083.054-.085.052-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.044-.118.044-.12.044-.122.042-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.035-.143.033-.144.033-.147.033-.148.031-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.009-.179.009-.179.007-.181.007-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.007-.179-.007-.179-.009-.178-.009-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.031-.146-.033-.145-.033-.143-.033-.141-.035-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.04-.126-.041-.124-.042-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.051-.093-.051-.09-.051-.087-.053-.085-.052-.083-.054-.08-.054-.077-.054v4.139zm0-5.666v.011l.001.02.003.022.004.021.005.022.006.021.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.024.018.023.019.024.021.025.022.024.023.024.024.025.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.051.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.043.171.043.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.021.23.02.233.018.236.017.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.013.241-.014.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.049.139-.049.136-.049.131-.051.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.049.023-.025.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.022.01-.023.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.153l-.077.054-.08.054-.083.053-.085.053-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.048-.105.048-.106.048-.109.046-.111.046-.114.046-.115.044-.118.044-.12.043-.122.043-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.034-.143.034-.144.033-.147.032-.148.032-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.024-.161.024-.162.023-.163.023-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.01-.178.01-.179.009-.179.007-.181.006-.182.006-.182.004-.184.003-.184.001-.185.001-.185-.001-.184-.001-.184-.003-.182-.004-.182-.006-.181-.006-.179-.007-.179-.009-.178-.01-.176-.01-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.023-.162-.023-.161-.024-.159-.024-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.032-.146-.032-.145-.033-.143-.034-.141-.034-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.041-.126-.041-.124-.041-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.048-.105-.048-.102-.048-.1-.05-.097-.049-.095-.051-.093-.051-.09-.052-.087-.052-.085-.053-.083-.053-.08-.054-.077-.054v4.153zm8.74-8.179l-.257.004-.254.005-.25.008-.247.011-.244.012-.241.014-.237.016-.233.018-.231.021-.226.022-.224.023-.22.026-.216.027-.212.028-.21.031-.205.032-.202.033-.198.034-.194.036-.191.038-.187.038-.183.04-.179.041-.175.042-.172.043-.168.043-.163.045-.16.046-.155.046-.152.048-.148.048-.143.048-.139.049-.136.05-.131.05-.126.051-.123.051-.118.051-.114.052-.11.052-.106.052-.101.052-.096.052-.092.052-.088.052-.083.052-.079.052-.074.051-.07.052-.065.051-.06.05-.056.05-.051.05-.023.025-.023.024-.021.024-.02.025-.019.024-.018.024-.017.023-.015.024-.014.023-.013.023-.012.023-.01.023-.01.022-.008.022-.006.023-.006.021-.004.022-.004.021-.001.021-.001.021.001.021.001.021.004.021.004.022.006.021.006.023.008.022.01.022.01.023.012.023.013.023.014.023.015.024.017.023.018.024.019.024.02.025.021.024.023.024.023.025.051.05.056.05.06.05.065.051.07.052.074.051.079.052.083.052.088.052.092.052.096.052.101.052.106.052.11.052.114.052.118.051.123.051.126.051.131.05.136.05.139.049.143.048.148.048.152.048.155.046.16.046.163.045.168.043.172.043.175.042.179.041.183.04.187.038.191.038.194.036.198.034.202.033.205.032.21.031.212.028.216.027.22.026.224.023.226.022.231.021.233.018.237.016.241.014.244.012.247.011.25.008.254.005.257.004.26.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.022.224-.023.22-.026.216-.027.212-.028.21-.031.205-.032.202-.033.198-.034.194-.036.191-.038.187-.038.183-.04.179-.041.175-.042.172-.043.168-.043.163-.045.16-.046.155-.046.152-.048.148-.048.143-.048.139-.049.136-.05.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.05.051-.05.023-.025.023-.024.021-.024.02-.025.019-.024.018-.024.017-.023.015-.024.014-.023.013-.023.012-.023.01-.023.01-.022.008-.022.006-.023.006-.021.004-.022.004-.021.001-.021.001-.021-.001-.021-.001-.021-.004-.021-.004-.022-.006-.021-.006-.023-.008-.022-.01-.022-.01-.023-.012-.023-.013-.023-.014-.023-.015-.024-.017-.023-.018-.024-.019-.024-.02-.025-.021-.024-.023-.024-.023-.025-.051-.05-.056-.05-.06-.05-.065-.051-.07-.052-.074-.051-.079-.052-.083-.052-.088-.052-.092-.052-.096-.052-.101-.052-.106-.052-.11-.052-.114-.052-.118-.051-.123-.051-.126-.051-.131-.05-.136-.05-.139-.049-.143-.048-.148-.048-.152-.048-.155-.046-.16-.046-.163-.045-.168-.043-.172-.043-.175-.042-.179-.041-.183-.04-.187-.038-.191-.038-.194-.036-.198-.034-.202-.033-.205-.032-.21-.031-.212-.028-.216-.027-.22-.026-.224-.023-.226-.022-.231-.021-.233-.018-.237-.016-.241-.014-.244-.012-.247-.011-.25-.008-.254-.005-.257-.004-.26-.001-.26.001z\"/></symbol></defs><defs><symbol id=\"clock\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M12 2c5.514 0 10 4.486 10 10s-4.486 10-10 10-10-4.486-10-10 4.486-10 10-10zm0-2c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm5.848 12.459c.202.038.202.333.001.372-1.907.361-6.045 1.111-6.547 1.111-.719 0-1.301-.582-1.301-1.301 0-.512.77-5.447 1.125-7.445.034-.192.312-.181.343.014l.985 6.238 5.394 1.011z\"/></symbol></defs><defs><marker id=\"arrowhead\" refX=\"7.9\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto-start-reverse\"><path d=\"M -1 0 L 10 5 L 0 10 z\"/></marker></defs><defs><marker id=\"crosshead\" markerWidth=\"15\" markerHeight=\"8\" orient=\"auto\" refX=\"4\" refY=\"4.5\"><path fill=\"none\" stroke=\"#000000\" stroke-width=\"1pt\" d=\"M 1,2 L 6,7 M 6,2 L 1,7\" style=\"stroke-dasharray: 0, 0;\"/></marker></defs><defs><marker id=\"filled-head\" refX=\"15.5\" refY=\"7\" markerWidth=\"20\" markerHeight=\"28\" orient=\"auto\"><path d=\"M 18,7 L9,13 L14,7 L9,1 Z\"/></marker></defs><defs><marker id=\"sequencenumber\" refX=\"15\" refY=\"15\" markerWidth=\"60\" markerHeight=\"40\" orient=\"auto\"><circle cx=\"15\" cy=\"15\" r=\"6\"/></marker></defs><g><rect x=\"50\" y=\"95\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"765\" height=\"39\" class=\"note\"/><text x=\"433\" y=\"100\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"433\">Initial Setup</tspan></text></g><g><rect x=\"307\" y=\"188\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"166\" height=\"58\" class=\"note\"/><text x=\"390\" y=\"193\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"390\">Generates high-quality</tspan></text><text x=\"390\" y=\"212\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"390\">structured extraction</tspan></text></g><g><rect x=\"50\" y=\"376\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"565\" height=\"39\" class=\"note\"/><text x=\"333\" y=\"381\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">API Request</tspan></text></g><g><rect x=\"50\" y=\"471\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"565\" height=\"115\" class=\"note\"/><text x=\"333\" y=\"476\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">1. System prompt</tspan></text><text x=\"333\" y=\"495\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">2. Initial text</tspan></text><text x=\"333\" y=\"514\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">3. example_output from Claude 3.5</tspan></text><text x=\"333\" y=\"533\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">4. New text for extraction</tspan></text><text x=\"333\" y=\"552\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">5. JSON schema</tspan></text></g><g><rect x=\"515\" y=\"626\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"150\" height=\"39\" class=\"note\"/><text x=\"590\" y=\"631\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"590\">Processing</tspan></text></g><g><rect x=\"473.5\" y=\"751\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"233\" height=\"77\" class=\"note\"/><text x=\"590\" y=\"756\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"590\">Learn from Claude 3.5's example</tspan></text><text x=\"590\" y=\"775\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"590\">Apply to new text</tspan></text><text x=\"590\" y=\"794\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"590\">Conform to JSON schema</tspan></text></g><g><rect x=\"50\" y=\"868\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"565\" height=\"39\" class=\"note\"/><text x=\"333\" y=\"873\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"333\">Results</tspan></text></g><text x=\"231\" y=\"149\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Provide initial text and extraction task</text><line x1=\"76\" y1=\"178\" x2=\"386\" y2=\"178\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"234\" y=\"261\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Return example_output (JSON)</text><line x1=\"389\" y1=\"292\" x2=\"79\" y2=\"292\" class=\"messageLine1\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"stroke-dasharray: 3, 3; fill: none;\"/><text x=\"431\" y=\"307\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Define ExtractScheme</text><line x1=\"76\" y1=\"336\" x2=\"786\" y2=\"336\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"331\" y=\"430\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Send API request with:</text><line x1=\"76\" y1=\"461\" x2=\"586\" y2=\"461\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"591\" y=\"680\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Process request using few-shot learning</text><path d=\"M 591,711 C 651,701 651,741 591,731\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"334\" y=\"922\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Return structured extraction for new text</text><line x1=\"589\" y1=\"951\" x2=\"79\" y2=\"951\" class=\"messageLine1\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"stroke-dasharray: 3, 3; fill: none;\"/><text x=\"76\" y=\"966\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Parse and analyze results</text><path d=\"M 76,997 C 136,987 136,1027 76,1017\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/></svg>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title \"few-shot\" Example from a \"stronger model\" or verified by expert (hidden)\n",
        "\n",
        "example_output = {\n",
        "  \"title\": \"An 'AI Scientist' Is Inventing and Running Its Own Experiments\",\n",
        "  \"publication_date\": \"Aug 21, 2024\",\n",
        "  \"main_topic\": \"AI-driven scientific research and experimentation\",\n",
        "  \"research_description\": \"Development of an 'AI scientist' capable of inventing, designing, and running its own machine learning experiments, producing research papers with incremental improvements on existing algorithms and ideas.\",\n",
        "  \"institutions_involved\": [\n",
        "    \"University of British Columbia\",\n",
        "    \"University of Oxford\",\n",
        "    \"Sakana AI\",\n",
        "    \"Allen Institute for AI\",\n",
        "    \"Hebrew University of Jerusalem\"\n",
        "  ],\n",
        "  \"key_researchers\": [\n",
        "    \"Jeff Clune\",\n",
        "    \"Tom Hope\"\n",
        "  ],\n",
        "  \"ai_technologies\": [\n",
        "    \"Large language models (LLMs)\",\n",
        "    \"Diffusion modeling\",\n",
        "    \"Deep neural networks\",\n",
        "    \"Open-ended learning\",\n",
        "    \"AI agents\"\n",
        "  ],\n",
        "  \"research_outcomes\": [\n",
        "    \"AI-generated research papers with incremental improvements on existing algorithms\",\n",
        "    \"Tweaks for improving image-generating techniques like diffusion modeling\",\n",
        "    \"Approaches for speeding up learning in deep neural networks\",\n",
        "    \"Development of AI programs that can learn through open-ended experimentation\",\n",
        "    \"Creation of an AI system that invents and builds AI agents\"\n",
        "  ],\n",
        "  \"potential_impacts\": [\n",
        "    \"Unlocking AI capabilities beyond human-generated training data\",\n",
        "    \"Enabling AI to learn in an open-ended fashion through experimentation\",\n",
        "    \"Potential for breakthrough ideas and scientific discoveries\",\n",
        "    \"Development of more powerful and reliable AI agents\",\n",
        "    \"Advancement in automating elements of scientific discovery\"\n",
        "  ],\n",
        "  \"ethical_concerns\": [\n",
        "    \"Potential dangers of generating misbehaving AI agents\",\n",
        "    \"Reliability and trustworthiness of AI-generated research\",\n",
        "    \"Implications for human involvement in scientific research and discovery\"\n",
        "  ],\n",
        "  \"keywords\": [\n",
        "    \"AI Scientist\",\n",
        "    \"Open-ended learning\",\n",
        "    \"Machine learning experiments\",\n",
        "    \"Artificial intelligence\",\n",
        "    \"Scientific automation\",\n",
        "    \"LLMs\",\n",
        "    \"Diffusion modeling\",\n",
        "    \"Deep neural networks\",\n",
        "    \"AI agents\",\n",
        "    \"Experimental design\"\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "npmTEGLx12dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title new text (hidden)\n",
        "new_text = \"\"\"\n",
        "Voyage AI is building RAG tools to make AI hallucinate less\n",
        "Kyle Wiggers\n",
        "Image Credits: Viktor Tanasiichuk / Getty Images\n",
        "\n",
        "AI tends to make things up. That's unappealing to just about anyone who uses it on a regular basis, but especially to businesses, for which fallacious results could hurt the bottom line. Half of workers responding to a recent survey from Salesforce say they worry answers from their company's generative AI-powered systems are inaccurate.\n",
        "\n",
        "While no technique can solve these \"hallucinations,\" some can help. For example, retrieval-augmented generation, or RAG, pairs an AI model with a knowledge base to provide the model supplemental info before it answers, serving as a sort of fact-checking mechanism.\n",
        "\n",
        "Entire businesses have been built on RAG, thanks to the sky-high demand for more reliable AI. Voyage AI is one of these. Founded by Stanford professor Tengyu Ma in 2023, Voyage powers RAG systems for companies including Harvey, Vanta, Replit, and SK Telecom.\n",
        "\n",
        "\"Voyage is on a mission to enhance search and retrieval accuracy and efficiency in enterprise AI,\" Ma told TechCrunch in an interview. \"Voyage solutions [are] tailored to specific domains, such as coding, finance, legal, and multilingual applications, and tailored to a company's data.\"\n",
        "\n",
        "To spin up RAG systems, Voyage trains AI models to convert text, documents, PDFs, and other forms of data into numerical representations called vector embeddings. Embeddings capture the meaning and relationships between different data points in a compact format, making them useful for search-related applications, like RAG.\n",
        "\n",
        "Voyage uses a particular type of embedding called contextual embedding, which captures not only the semantic meaning of data but the context in which the data appears. For example, given the word \"bank\" in the sentences \"I sat on the bank of the river\" and \"I deposited money in the bank,\" Voyage's embedding models would generate different vectors for each instance of \"bank\" — reflecting the different meanings implied by the context.\n",
        "\n",
        "Voyage hosts and licenses its models for on-premises, private cloud, or public cloud use, and fine-tunes its models for clients that opt to pay for this service. The company isn't unique in that regard — OpenAI, too, has a tailorable embedding service — but Ma claims that Voyage's models deliver better performance at lower costs.\n",
        "\n",
        "\"In RAG, given a question or query, we first retrieve relevant info from an unstructured knowledge base — like a librarian searching books from a library,\" he explained. \"Conventional RAG methods often struggle with context loss during information encoding, leading to failures in retrieving relevant information. Voyage's embedding models have best-in-class retrieval accuracy, which translates to the end-to-end response quality of RAG systems.\"\n",
        "\n",
        "Lending weight to those bold claims is an endorsement from OpenAI chief rival Anthropic; an Anthropic support doc describes Voyage's models as \"state of the art.\"\n",
        "\n",
        "\"Voyage's approach uses vector embeddings trained on the company's data to provide context-aware retrievals,\" Ma said, \"which significantly improves retrieval accuracy.\"\n",
        "\n",
        "Ma says that Palo Alto-based Voyage has just over 250 customers. He declined to answer questions about revenue.\n",
        "\n",
        "In September, Voyage, which has around a dozen employees, closed a $20 million Series A round led by CRV with participation from Wing VC, Conviction, Snowflake, and Databricks. Ma says that the cash infusion, which brings Voyage's total raised to $28 million, will support the launch of new embedding models and will let the company double its size.\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "RPtAgusq2PCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the LLM with the JSON schema enforced in the response_format\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    response_format={\"type\": \"json_object\", \"schema\": ExtractScheme.model_json_schema()},\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with extracting structured information from a text related to AI research and technology. Follow the schema provided to extract the relevant details. Do not invent information that is not in the provided text.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Extract case information from the following text: {text}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": f\"{example_output}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Extract case information from the following text: {new_text}\"\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Parse and print the extracted information\n",
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ],
      "metadata": {
        "id": "9OcaSalh1wSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Approaches\n",
        "Let's compare the three approaches we've used for extracting structured information:\n",
        "\n",
        "1. **Providing the schema in the prompt**: This method is more flexible and works with a wider range of models. However, it relies on the model's ability to understand and follow the schema correctly.\n",
        "\n",
        "2. **Using `response_format`**: This method enforces the schema at the API level, ensuring a strictly formatted response. It's more robust but may not be supported by all models.\n",
        "\n",
        "3. **Few-shot learning with a large model example**: This approach involves using a more capable model (like Claude 3.5) to generate a high-quality structured extraction example, which is then used to guide a smaller model (like LLaMA 3.1 8B) in performing similar extractions on new text. The steps include:\n",
        "   a. Generate an example extraction using a large model\n",
        "   b. Define a JSON schema based on this example\n",
        "   c. Provide the example, schema, and new text to a smaller model\n",
        "   d. The smaller model learns from the example and applies it to the new text\n",
        "\n",
        "The few-shot learning approach combines elements of both previous methods. It leverages the power of a large model to create a high-quality example, then uses that example along with a schema to guide a smaller model. This can potentially improve the performance of the smaller model while still maintaining the efficiency benefits of using a less resource-intensive model for the main task.\n",
        "\n",
        "In practice, you might choose one approach over the others based on your specific use case, the models you're working with, the level of strictness required in your application, and the computational resources available. Here are some considerations:\n",
        "\n",
        "- **Flexibility vs. Strictness**: The prompt-based approach offers more flexibility, while `response_format` provides stricter adherence to the schema.\n",
        "- **Model Compatibility**: Not all models support `response_format`, so the prompt-based or few-shot approaches may be necessary in some cases.\n",
        "- **Resource Efficiency**: The few-shot approach allows you to use a smaller, more efficient model for the main task while still benefiting from the capabilities of a larger model.\n",
        "- **Accuracy and Consistency**: The few-shot approach may improve the accuracy and consistency of smaller models by providing them with a high-quality example to learn from.\n",
        "- **Complexity**: The few-shot approach is more complex to implement as it involves multiple steps and models, but it may offer a good balance between performance and efficiency."
      ],
      "metadata": {
        "id": "tTTnZbqI1m4O"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/miniconda3/share/jupyter/kernels/python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}